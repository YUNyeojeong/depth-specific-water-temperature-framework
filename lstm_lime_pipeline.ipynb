{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "sc = MinMaxScaler() \n",
    "from sklearn import datasets, ensemble, model_selection\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "#pip install lime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of             date  month  inflow  AirTemp(°C)  CC_Pre(mm)  \\\n",
      "0     2016-01-01      1  14.494         -1.7         0.0   \n",
      "1     2016-01-02      1  14.476          2.7         0.0   \n",
      "2     2016-01-03      1  14.513          2.0         0.0   \n",
      "3     2016-01-04      1  14.506          1.4         0.0   \n",
      "4     2016-01-05      1  14.512         -3.1         0.0   \n",
      "...          ...    ...     ...          ...         ...   \n",
      "1822  2020-12-27     12   7.673          2.2         0.0   \n",
      "1823  2020-12-28     12   7.735          2.9         0.3   \n",
      "1824  2020-12-29     12   2.103         -0.4         0.0   \n",
      "1825  2020-12-30     12   2.260         -9.5         0.0   \n",
      "1826  2020-12-31     12   0.000         -9.6         0.0   \n",
      "\n",
      "      maximum instantaneous wind speed  maximum wind speed  WindSpeed(m/s)  \\\n",
      "0                                  200                 180             0.7   \n",
      "1                                  180                 200             0.5   \n",
      "2                                  270                 340             0.5   \n",
      "3                                  200                 200             1.7   \n",
      "4                                  200                 230             1.0   \n",
      "...                                ...                 ...             ...   \n",
      "1822                                50                 290             0.5   \n",
      "1823                               340                 270             0.5   \n",
      "1824                               250                 230             1.2   \n",
      "1825                               250                 250             2.7   \n",
      "1826                               200                 180             1.7   \n",
      "\n",
      "      DewPoint(°C)  Relative Humidity(%)  ...  depth90  depth91  depth92  \\\n",
      "0             -3.0                  90.8  ...     3.27     3.27     0.00   \n",
      "1              0.3                  85.0  ...     5.16     4.72     4.39   \n",
      "2              1.2                  95.3  ...     4.95     4.67     4.48   \n",
      "3             -7.2                  61.0  ...     4.88     4.61     4.47   \n",
      "4            -12.2                  55.1  ...     4.78     4.54     4.44   \n",
      "...            ...                   ...  ...      ...      ...      ...   \n",
      "1822          -2.6                  71.3  ...     5.03     5.03     5.03   \n",
      "1823           0.0                  83.1  ...     5.03     5.03     5.03   \n",
      "1824          -4.0                  78.6  ...     5.04     5.04     5.04   \n",
      "1825         -20.3                  41.8  ...     5.04     5.04     5.04   \n",
      "1826         -18.3                  51.0  ...     5.04     5.04     5.04   \n",
      "\n",
      "      depth93  depth94  depth95  depth96  depth97  depth98  depth99  \n",
      "0        0.00     0.00     0.00     0.00     0.00     0.00     0.00  \n",
      "1        4.22     4.12     4.11     0.00     0.00     0.00     0.00  \n",
      "2        4.34     4.21     4.20     0.00     0.00     0.00     0.00  \n",
      "3        4.37     4.25     4.25     0.00     0.00     0.00     0.00  \n",
      "4        4.37     4.28     4.28     0.00     0.00     0.00     0.00  \n",
      "...       ...      ...      ...      ...      ...      ...      ...  \n",
      "1822     5.03     5.03     5.03     5.03     5.03     5.03     5.03  \n",
      "1823     5.03     5.03     5.03     5.03     5.03     5.03     5.03  \n",
      "1824     5.04     5.04     5.04     5.04     5.04     5.04     5.04  \n",
      "1825     5.04     5.04     5.04     5.04     5.04     5.04     5.04  \n",
      "1826     5.04     5.04     5.04     5.04     5.04     5.04     5.04  \n",
      "\n",
      "[1827 rows x 120 columns]>\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r\"D:\\yPy\\SY\\sy_16to20_W2_obs.csv\")\n",
    "print(df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.set_index('date')\n",
    "data=(df-df.min())/(df.max()-df.min())\n",
    "\n",
    "\n",
    "X1 = data[['inflow', 'AirTemp(°C)', 'CC_Pre(mm)', 'maximum instantaneous wind speed', 'maximum wind speed', 'WindSpeed(m/s)', 'DewPoint(°C)', 'Relative Humidity(%)', 'Vapor Pressure(hPa)', 'Local Atmospheric Pressure(hPa)', 'Sea Level Pressure(hPa)', 'Solar Radiation(MJ/m2)', 'Cloud(1/10)', 'Ground Temp(°C)', 'Small-Scale Evaporation(mm)']]\n",
    "y1 = data['depth60']\n",
    "X_traindepth60, X_testdepth60, y_traindepth60, y_testdepth60 =train_test_split(X1, y1, random_state=0, test_size=0.3, shuffle=False)\n",
    "X_traindepth60 = X_traindepth60.values \n",
    "X_testdepth60= X_testdepth60.values \n",
    "y_traindepth60 = y_traindepth60.values \n",
    "y_testdepth60 = y_testdepth60.values \n",
    "X_traindepth60 = X_traindepth60.reshape(X_traindepth60.shape[0], X_traindepth60.shape[1], 1) \n",
    "X_testdepth60 = X_testdepth60.reshape(X_testdepth60.shape[0], X_traindepth60.shape[1], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "79/79 [==============================] - 2s 7ms/step - loss: 0.1133 - mse: 0.1133 - val_loss: 0.0600 - val_mse: 0.0600\n",
      "Epoch 2/1000\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0414 - mse: 0.0414 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 3/1000\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 4/1000\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0106 - val_mse: 0.0106\n",
      "Epoch 5/1000\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 6/1000\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 7/1000\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 8/1000\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0080 - val_mse: 0.0080\n",
      "Epoch 9/1000\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0073 - val_mse: 0.0073\n",
      "Epoch 10/1000\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0067 - val_mse: 0.0067\n",
      "Epoch 11/1000\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0060 - val_mse: 0.0060\n",
      "Epoch 12/1000\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "Epoch 13/1000\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0050 - val_mse: 0.0050\n",
      "Epoch 14/1000\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0048 - val_mse: 0.0048\n",
      "Epoch 15/1000\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0050 - val_mse: 0.0050\n",
      "Epoch 16/1000\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0048 - val_mse: 0.0048\n",
      "Epoch 17/1000\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 18/1000\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 19/1000\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0052 - val_mse: 0.0052\n",
      "Epoch 20/1000\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0049 - val_mse: 0.0049\n",
      "Epoch 21/1000\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0052 - val_mse: 0.0052\n",
      "Epoch 22/1000\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0048 - val_mse: 0.0048\n",
      "Epoch 23/1000\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0058 - val_mse: 0.0058\n",
      "Epoch 24/1000\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "Epoch 25/1000\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0048 - val_mse: 0.0048\n",
      "Epoch 26/1000\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0049 - val_mse: 0.0049\n",
      "Epoch 27/1000\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0058 - val_mse: 0.0058\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 20)                1760      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                420       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,511\n",
      "Trainable params: 2,511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Adam = keras.optimizers.Adam(learning_rate=0.0001)  \n",
    "model = Sequential()\n",
    "model.add(LSTM(20, input_shape=(15, X_traindepth60.shape[2])))  # 입력 모양 수정\n",
    "model.add(Dense(20, activation='tanh'))\n",
    "model.add(Dense(10, activation='tanh'))\n",
    "model.add(Dense(10, activation='tanh'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer=Adam, metrics=['mse'])  # 회귀 문제에서는 'mse'를 사용합니다.\n",
    "\n",
    "# 조기 종료 설정\n",
    "early_stopping = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_traindepth60, y_traindepth60, epochs=1000, batch_size=13, verbose=1, callbacks=[early_stopping],validation_split=0.2)\n",
    "\n",
    "# 모델 요약 출력\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 31\u001b[0m\n\u001b[0;32m     24\u001b[0m plot_model(model,\n\u001b[0;32m     25\u001b[0m            to_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel.png\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     26\u001b[0m            show_shapes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     27\u001b[0m            show_layer_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     28\u001b[0m            dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m96\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# 바로 출력\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m display(\u001b[43mImage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32md:\\yPy\\.venv\\Lib\\site-packages\\IPython\\core\\display.py:970\u001b[0m, in \u001b[0;36mImage.__init__\u001b[1;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata, alt)\u001b[0m\n\u001b[0;32m    968\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munconfined \u001b[38;5;241m=\u001b[39m unconfined\n\u001b[0;32m    969\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malt \u001b[38;5;241m=\u001b[39m alt\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mImage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m, {}):\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m=\u001b[39m metadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32md:\\yPy\\.venv\\Lib\\site-packages\\IPython\\core\\display.py:327\u001b[0m, in \u001b[0;36mDisplayObject.__init__\u001b[1;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 327\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_data()\n",
      "File \u001b[1;32md:\\yPy\\.venv\\Lib\\site-packages\\IPython\\core\\display.py:1005\u001b[0m, in \u001b[0;36mImage.reload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1003\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[39;00m\n\u001b[0;32m   1004\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed:\n\u001b[1;32m-> 1005\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mImage\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1006\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretina:\n\u001b[0;32m   1007\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retina_shape()\n",
      "File \u001b[1;32md:\\yPy\\.venv\\Lib\\site-packages\\IPython\\core\\display.py:353\u001b[0m, in \u001b[0;36mDisplayObject.reload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    352\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_flags \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 353\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_flags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    354\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;66;03m# Deferred import\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model.png'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import Image, display\n",
    "import numpy as np\n",
    "\n",
    "# 예시 더미데이터 (실제 데이터로 교체)\n",
    "X_traindepth60 = np.random.rand(100, 15, 8)  # (샘플수, 타임스텝, 피처수)\n",
    "y_traindepth60 = np.random.rand(100, 1)\n",
    "\n",
    "# 모델 정의\n",
    "Adam = optimizers.Adam(learning_rate=0.0001)\n",
    "model = Sequential()\n",
    "model.add(LSTM(20, input_shape=(15, X_traindepth60.shape[2])))\n",
    "model.add(Dense(20, activation='tanh'))\n",
    "model.add(Dense(10, activation='tanh'))\n",
    "model.add(Dense(10, activation='tanh'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer=Adam, metrics=['mse'])\n",
    "\n",
    "# 모델 구조 그림 저장\n",
    "plot_model(model,\n",
    "           to_file='model.png',\n",
    "           show_shapes=True,\n",
    "           show_layer_names=True,\n",
    "           dpi=96)\n",
    "\n",
    "# 바로 출력\n",
    "display(Image(filename='model.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIME을 사용하여 전역적인 특성 중요도를 얻는 방법. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_testdepth60 shape: (1278, 15, 1)\n",
      "X1.columns length: 15\n",
      "X_testdepth60 shape: (549, 15)\n",
      "X_traindepth60 shape: (1278, 15)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_testdepth60 shape:\", X_traindepth60.shape)  # 차원 확인\n",
    "print(\"X1.columns length:\", len(X1.columns))  # feature_names의 길이 확인\n",
    "\n",
    "# X_traindepth60가 3차원이라면 2차원으로 변환\n",
    "if len(X_traindepth60.shape) == 3:\n",
    "    X_traindepth60_reshaped = X_traindepth60.reshape(X_traindepth60.shape[0], X_traindepth60.shape[1])  # 2차원으로 재구조화\n",
    "    # X_traindepth60가 3차원이라면 2차원으로 변환\n",
    "if len(X_testdepth60.shape) == 3:\n",
    "    X_testdepth60_reshaped = X_testdepth60.reshape(X_testdepth60.shape[0], X_testdepth60.shape[1])  # 2차원으로 재구조화\n",
    "\n",
    "print(\"X_testdepth60 shape:\", X_testdepth60_reshaped.shape)  # 차원 확인\n",
    "print(\"X_traindepth60 shape:\", X_traindepth60_reshaped.shape)  # 차원 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 1ms/step\n",
      "MAE : 0.1777\n",
      "RMSE: 0.2316\n",
      "R²  : 0.0808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\yPy\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "y_pred = model.predict(X_testdepth60)\n",
    "\n",
    "# 1차원으로 변환 (shape 일치시키기)\n",
    "y_true = np.ravel(y_testdepth60)\n",
    "y_pred = np.ravel(y_pred)\n",
    "\n",
    "# 지표 계산\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(f\"MAE : {mae:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R²  : {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"d:\\yPy\\.venv\\Lib\\site-packages\\keras\\engine\\training.py\", line 2169, in predict_function  *\n        return step_function(self, iterator)\n    File \"d:\\yPy\\.venv\\Lib\\site-packages\\keras\\engine\\training.py\", line 2155, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\yPy\\.venv\\Lib\\site-packages\\keras\\engine\\training.py\", line 2143, in run_step  **\n        outputs = model.predict_step(data)\n    File \"d:\\yPy\\.venv\\Lib\\site-packages\\keras\\engine\\training.py\", line 2111, in predict_step\n        return self(x, training=False)\n    File \"d:\\yPy\\.venv\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"d:\\yPy\\.venv\\Lib\\site-packages\\keras\\layers\\rnn\\lstm.py\", line 615, in call\n        timesteps = input_shape[0] if self.time_major else input_shape[1]\n\n    TypeError: Exception encountered when calling layer 'lstm' (type LSTM).\n    \n    'NoneType' object is not subscriptable\n    \n    Call arguments received by layer 'lstm' (type LSTM):\n      • inputs=tf.Tensor(shape=<unknown>, dtype=float32)\n      • mask=None\n      • training=False\n      • initial_state=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# 테스트 데이터의 각 샘플에 대해 LIME 실행\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(X_testdepth60_reshaped\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m---> 30\u001b[0m     exp \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_testdepth60_reshaped\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_testdepth60_reshaped\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;66;03m# 각 특성의 중요도 저장\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     importance_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(exp\u001b[38;5;241m.\u001b[39mas_list())\n",
      "File \u001b[1;32md:\\yPy\\.venv\\Lib\\site-packages\\lime\\lime_tabular.py:355\u001b[0m, in \u001b[0;36mLimeTabularExplainer.explain_instance\u001b[1;34m(self, data_row, predict_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001b[0m\n\u001b[0;32m    348\u001b[0m     scaled_data \u001b[38;5;241m=\u001b[39m (data \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mmean_) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale_\n\u001b[0;32m    349\u001b[0m distances \u001b[38;5;241m=\u001b[39m sklearn\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mpairwise_distances(\n\u001b[0;32m    350\u001b[0m         scaled_data,\n\u001b[0;32m    351\u001b[0m         scaled_data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m    352\u001b[0m         metric\u001b[38;5;241m=\u001b[39mdistance_metric\n\u001b[0;32m    353\u001b[0m )\u001b[38;5;241m.\u001b[39mravel()\n\u001b[1;32m--> 355\u001b[0m yss \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minverse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;66;03m# for classification, the model needs to provide a list of tuples - classes\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;66;03m# along with prediction probabilities\u001b[39;00m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassification\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "Cell \u001b[1;32mIn[7], line 26\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(X):\n\u001b[1;32m---> 26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mflatten()\n",
      "File \u001b[1;32md:\\yPy\\.venv\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filedgl_dspv.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    File \"d:\\yPy\\.venv\\Lib\\site-packages\\keras\\engine\\training.py\", line 2169, in predict_function  *\n        return step_function(self, iterator)\n    File \"d:\\yPy\\.venv\\Lib\\site-packages\\keras\\engine\\training.py\", line 2155, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\yPy\\.venv\\Lib\\site-packages\\keras\\engine\\training.py\", line 2143, in run_step  **\n        outputs = model.predict_step(data)\n    File \"d:\\yPy\\.venv\\Lib\\site-packages\\keras\\engine\\training.py\", line 2111, in predict_step\n        return self(x, training=False)\n    File \"d:\\yPy\\.venv\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"d:\\yPy\\.venv\\Lib\\site-packages\\keras\\layers\\rnn\\lstm.py\", line 615, in call\n        timesteps = input_shape[0] if self.time_major else input_shape[1]\n\n    TypeError: Exception encountered when calling layer 'lstm' (type LSTM).\n    \n    'NoneType' object is not subscriptable\n    \n    Call arguments received by layer 'lstm' (type LSTM):\n      • inputs=tf.Tensor(shape=<unknown>, dtype=float32)\n      • mask=None\n      • training=False\n      • initial_state=None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.inspection import permutation_importance\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "import random\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# 특성 이름 설정\n",
    "feature_names = list(X1.columns)  # 특성 이름 리스트로 변환\n",
    "\n",
    "# LIME explainer 객체 생성\n",
    "explainer = LimeTabularExplainer(\n",
    "    X_traindepth60_reshaped,\n",
    "    feature_names=feature_names,\n",
    "    mode='regression',  # 회귀 모드로 설정\n",
    "    discretize_continuous=False\n",
    ")\n",
    "\n",
    "# 각 샘플에 대한 특성 중요도를 저장할 배열 초기화\n",
    "global_importance_values = np.zeros((X_testdepth60_reshaped.shape[0], X_testdepth60_reshaped.shape[1]))\n",
    "\n",
    "# 예측 함수 정의 (회귀)\n",
    "def predict(X):\n",
    "    return model.predict(X).flatten()  # 모델의 예측 값을 flatten\n",
    "\n",
    "# 테스트 데이터의 각 샘플에 대해 LIME 실행\n",
    "for i in range(X_testdepth60_reshaped.shape[0]):\n",
    "    exp = explainer.explain_instance(X_testdepth60_reshaped[i], predict, num_features=X_testdepth60_reshaped.shape[1])\n",
    "    # 각 특성의 중요도 저장\n",
    "    importance_dict = dict(exp.as_list())\n",
    "    global_importance_values[i] = [importance_dict.get(feature, 0) for feature in feature_names]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inflow, 0.0006\n",
      "AirTemp(°C), 0.0038\n",
      "CC_Pre(mm), 0.0009\n",
      "maximum instantaneous wind speed, 0.0053\n",
      "maximum wind speed, 0.0060\n",
      "WindSpeed(m/s), 0.0032\n",
      "DewPoint(°C), 0.0065\n",
      "Relative Humidity(%), 0.0056\n",
      "Vapor Pressure(hPa), 0.0067\n",
      "Local Atmospheric Pressure(hPa), 0.0038\n",
      "Sea Level Pressure(hPa), 0.0019\n",
      "Solar Radiation(MJ/m2), -0.0028\n",
      "Cloud(1/10), -0.0150\n",
      "Ground Temp(°C), -0.0292\n",
      "Small-Scale Evaporation(mm), -0.0481\n"
     ]
    }
   ],
   "source": [
    "# 전역적인 특성 중요도 계산 (각 특성의 중요도를 평균)\n",
    "global_importance = np.mean(global_importance_values, axis=0)\n",
    "\n",
    "# 전역적인 특성 중요도 출력 및 저장\n",
    "importance_data = []\n",
    "\n",
    "for i, importance in enumerate(global_importance):\n",
    "    print('%s, %.4f' % (feature_names[i], importance))\n",
    "    importance_data.append({feature_names[i], importance})\n",
    "\n",
    "# 데이터를 데이터프레임으로 변환\n",
    "#df = pd.DataFrame(importance_data)\n",
    "\n",
    "# CSV 파일로 저장\n",
    "df.to_csv(r'D:\\yPy\\SY\\sy_LIME_depth60.csv', index=False, mode='w', encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
